% -*- mode: Noweb; noweb-code-mode: caml-mode -*-

% Grades     ::=    "%%Grades:" Quality Importance Urgency
% Quality    ::=    A|B|C|D|E
% Importance ::=    Central|Subsystem|Peripheral
% Urgency    ::=    Immediate|Soon|Later
%
% Example (at beginning of line): %%Grades: B Central Soon

% Todo: parse %foo as abbreviation for $foo(). The change is already
% marked in the code below. It causes a shift/reduce conflict that is
% properly resolved. However, it would be nice to use precedences to
% avoid it. --CL Fri Aug  9 15:07:22 EDT 2002

% ------------------------------------------------------------------  
\section{Lexical Analysis}\label{sec:scanner}
% ------------------------------------------------------------------  

The scanner for lexical analysis is generated from a specification for
\ocaml~Lex. 

The generated scanner keeps track of its current position in its
input stream by counting the bytes it consumes.  In order to maintain
the more useful information of the current line and column in the
input we maintain some state in a source map which maps input stream
positions to a file name, line number, column number triple.  The
source map is passed as a parameter [[map]] into the scanner.

The first action of the parser is to place a sync point into the
source map.  This guarantees that every position in the input can be
maped to a location.  The fist character is always in line 1 and
column 1 in [[file]].

Whenever the scanner encounters a newline character it places a new
sync point for the following character into the source map.

<<scan.mli>>=
val scan : Srcmap.map -> Lexing.lexbuf -> Parse.token
val tok2str : Parse.token -> string
<<scan.mll>>=
{
    <<prolog>>
}
@ 
<<prolog>>=
module P = Parse    (* tokens are defined here *)
module E = Error

let nl lexbuf map =
    let next = (Lexing.lexeme_start lexbuf) + 1     in
        Srcmap.nl map next
    
@ The tab character is one byte long, but moves the cursor additional
$x$ positions to the right.  The number $x$ of virtual spaces depends
on the column $c$ of the tab:
            $$x = 7 - (c~\textrm{mod}~8)$$ 
Whenever the scanner encounters a tab character it calls the [[tab]]
function to place a sync point into the source map.  We currently
ignore tabs by not placing a sync point in the [[map]].  Sync points
are explained in section \ref{srcmap} about source code position
tracking.
<<prolog>>=
let tab lexbuf map = ()
@ 
The current location can be obtained by passing the current position
to [[Srcmap.loc]]:
<<prolog>>=
let location lexbuf map =
    Srcmap.location map (Lexing.lexeme_start lexbuf)
     
let error lexbuf msg = Error.error msg
@ 
We define some helpers; [[get]] returns the matched string and is
quite intuitive when called as [[get lexbuf]].
<<prolog>>=
let get         = Lexing.lexeme
let getchar     = Lexing.lexeme_char
let strlen      = String.length
let pos_start   = Lexing.lexeme_start
let pos_end     = Lexing.lexeme_end
let substr      = Auxfuns.substr
@
All keywords are stored in a hash table that maps them to tokens;
[[keyword s]] tries to lookup [[s]] in the table of keywords and
returns the matching token or raises [[Not_found]].  Keywords are not
directly encoded into the automaton of the scanner because this is
notorious for overflowing the tables of the automaton's
implementation.

<<prolog>>=
let keywords    = Hashtbl.create 127
let keyword s   = Hashtbl.find keywords s

let _ = Array.iter (fun (str,tok) -> Hashtbl.add keywords str tok)
    [|("aborts"         , P.ABORTS)
    ; ("align"          , P.ALIGN)
    ; ("aligned"        , P.ALIGNED)
    ; ("also"           , P.ALSO)
    ; ("as"             , P.AS)
    ; ("big"            , P.BIG)
    ; ("byteorder"      , P.BYTEORDER)
    ; ("case"           , P.CASE)
    ; ("const"          , P.CONST)
    ; ("continuation"   , P.CONTINUATION)
    ; ("cut"            , P.CUT)
    ; ("cuts"           , P.CUTS)
    ; ("else"           , P.ELSE)
    ; ("equal"          , P.EQUAL)
    ; ("export"         , P.EXPORT)
    ; ("fails"          , P.FAILS)
    ; ("foreign"        , P.FOREIGN)
    ; ("goto"           , P.GOTO)
    ; ("if"             , P.IF)
    ; ("import"         , P.IMPORT)
    ; ("in"             , P.IN)
    ; ("invariant"      , P.INVARIANT)
    ; ("jump"           , P.JUMP)
    ; ("limitcheck"     , P.LIMITCHECK)
    ; ("little"         , P.LITTLE)
    ; ("memsize"        , P.MEMSIZE)
    ; ("never"          , P.NEVER)
    ; ("pragma"         , P.PRAGMA)
    ; ("register"       , P.REGISTER)
    ; ("reads"          , P.READS)
    ; ("return"         , P.RETURN)
    ; ("returns"        , P.RETURNS)
    ; ("section"        , P.SECTION)
    ; ("semi"           , P.SEMI)
    ; ("span"           , P.SPAN)
    ; ("stackdata"      , P.STACKDATA)
    ; ("switch"         , P.SWITCH)
    ; ("target"         , P.TARGET)
    ; ("targets"        , P.TARGETS)
    ; ("to"             , P.TO)
    ; ("typedef"        , P.TYPEDEF)
    ; ("unicode"        , P.UNICODE)
    ; ("unwinds"        , P.UNWINDS)
    ; ("writes"         , P.WRITES)

    ; ("float"          , P.FLOATREPR)
    ; ("charset"        , P.CHARSET)
    ; ("pointersize"    , P.PTRSIZE)
    ; ("wordsize"       , P.WRDSIZE)

    |]
@

% ------------------------------------------------------------------  
\subsection{Declarations for Regular Expressions}
% ------------------------------------------------------------------  
<<scan.mll>>=
let digit       = ['0'-'9']
let octal       = ['0'-'7']
let hex         = ['0'-'9' 'A'-'F' 'a'-'f']

let printable   = [' '-'~']     (* add 8bit chars *)
let alpha       = ['a'-'z' 'A'-'Z']
let misc        = ['.' '_' '$' '@']

let escape      = ['\\' '\'' '"' 'a' 'b' 'f' 'n' 'r' 't' '?' ]

let sign        = ['+' '-']
let nat         = digit+
let uint        = ['1'-'9'] digit* ['u' 'U']    (* unsigned decimal *)
let zerou       = '0' ['u' 'U']                 (* unsigned decimal zero *)
let hexint      = '0' ['x' 'X'] hex+            (* hex *)
let octint      = '0' digit*                    (* octal *)
let sint        = ['1'-'9'] digit*         (* signed decimal *)
let frac        = nat '.' nat
let exp         = ['e''E'] sign? nat
let float       = frac exp? 
                | nat exp

let cxxcomment  = "//" [^ '\n']*
                
let id          = (alpha | misc) (alpha | misc | digit)*
let ws          = [' ' '\012' '\r']  (* SP FF CR *)
let nl          = '\n'          
let tab         = '\t'
@
% ------------------------------------------------------------------  
\subsection{The Main Lexer}
% ------------------------------------------------------------------  

The entry point for the lexer is the [[scan]] function. When a
source code map [[map]] is applied to it, it becomes a lexer
function suitable for a parser generated by \textsc{ocamllex}.
<<scanner entry point>>=
let scan map lexbuf =
    token lexbuf map
@
When the lexer is called is enters the [[token]] context where it
recognizes all keywords and simple tokens.  For complex tokens like
strings or comments it branches into special contexts.
<<scan.mll>>=
rule token = parse
    eof         { fun map -> P.EOF          }
  | ws+         { fun map -> token lexbuf map }
  | tab         { fun map -> tab lexbuf map; token lexbuf map }
  | nl          { fun map -> nl lexbuf map ; token lexbuf map }
  | nl ws* '#'  { fun map -> line lexbuf map 0; token lexbuf map }
  | ws* '#'     { fun map -> 
                  if Lexing.lexeme_start lexbuf = 0 then 
                        ( line lexbuf map 0
                        ; token lexbuf map
                        )
                  else
                        error lexbuf "illegal character" 
                }
  | ";"         { fun map -> P.SEMI         }
  | ":"         { fun map -> P.COLON        }
  | "::"        { fun map -> P.CCOLON       }
  | ","         { fun map -> P.COMMA        }
  | ".."        { fun map -> P.DOTDOT       }
  
  | "("         { fun map -> P.LPAREN       }
  | ")"         { fun map -> P.RPAREN       }
  | "{"         { fun map -> P.LBRACE       }
  | "}"         { fun map -> P.RBRACE       }
  | "["         { fun map -> P.LBRACKET     }
  | "]"         { fun map -> P.RBRACKET     }
  | "%%"        { fun map -> P.PPERCENT     }

  
  | "="         { fun map -> P.EQUAL        }
  

  (* infix/prefix operators *)
  
  | "+"         { fun map -> P.PLUS(get lexbuf)      }
  | "-"         { fun map -> P.MINUS(get lexbuf)     }
  | "*"         { fun map -> P.STAR(get lexbuf)      }
  | "/"         { fun map -> P.SLASH(get lexbuf)     }
  | "%"         { fun map -> P.PERCENT(get lexbuf)   }
  | "@>>"        { fun map -> P.GGREATER(get lexbuf)  }
  | "@<<"        { fun map -> P.LLESS(get lexbuf)     }
  | "&"         { fun map -> P.AMPERSAND(get lexbuf) }
  | "|"         { fun map -> P.BAR(get lexbuf)       }
  | "^"         { fun map -> P.CARET(get lexbuf)     }
  | "~"         { fun map -> P.TILDE(get lexbuf)     }
  | "=="        { fun map -> P.EEQ(get lexbuf)       }
  | "!="        { fun map -> P.NEQ(get lexbuf)       }
  | "<"         { fun map -> P.LT(get lexbuf)        }
  | "<="        { fun map -> P.LEQ(get lexbuf)       }
  | ">"         { fun map -> P.GT(get lexbuf)        }
  | ">="        { fun map -> P.GEQ(get lexbuf)       }

  | "`" id "`"  { fun map -> P.INFIXOP(substr 1 (-1) (get lexbuf)) }
              
  | "bits" nat  { fun map -> 
                  let s = substr 4 0 (get lexbuf) in
                  P.BITSn (int_of_string s)
                }
@
An identifier is an [[ID]] unless it is a reserved word.  When it is
the reserved word [[pragma]] the [[PRAGMA]] token is returned by
[[keyword]] and we switch to the special [[pragma1]] context. 
<<scan.mll>>=
  | id          { fun map ->  
                  let s  = get lexbuf in 
                  let k  = try keyword s with Not_found -> P.ID s in
                    if k = P.PRAGMA then pragma1 lexbuf map else k  
                } 
  | '%' id      { fun map ->
                  let s = substr 1 0 (get lexbuf)
                  in P.PRIMOP(s)
                }
  | float       { fun map -> P.FLT  (get lexbuf) }
  | sint        { fun map -> P.SINT (get lexbuf) }
  | uint        { fun map -> P.UINT (get lexbuf) }
  | zerou       { fun map -> P.UINT (get lexbuf) }
  | hexint      { fun map -> P.UINT (get lexbuf) }
  | octint      { fun map -> P.UINT (get lexbuf) }
  
  | "/*"        { fun map -> comment1 lexbuf map }
  | cxxcomment  { fun map -> token lexbuf map (* skip comment *) }
  
  | "\""        { fun map -> string  lexbuf map (Buffer.create 80) }
  | "'"         { fun map -> character lexbuf map } 
 
  | _           { fun map -> error lexbuf "illegal character" }
@

% ------------------------------------------------------------------  
\subsection{Character Literals}
% ------------------------------------------------------------------  

We decode charcter literals to integers here, using some helper
functions from the prolog. We use a continuation style: the result is
passed to the [[character_end]] lexer which should recognize the end of
the literal and return the value. This way we can write a lexer for
escape sequences that we can re-use for strings.

The first two rules match each one character. Since [[printable]]
includes the backslash it is critical that the rule for backslash comes
first, because in the case of two matches of the same length the first
one is chosen!
<<scan.mll>>=
and character = parse
    '\\'                        { fun map ->
                                  let i = escape lexbuf in
                                  if i >= 256 then
                                    error lexbuf "character literal too large"
                                  else  
                                    character_end lexbuf map i
                                }  
  | printable                   { fun map -> 
                                  let c = getchar lexbuf 0 in
                                  character_end lexbuf map (Char.code c)   
                                }
                                  
  | _                           { fun map ->
                                  error lexbuf 
                                    ( "illegal character literal: "
                                    ^  get lexbuf
                                    )
                                }

and character_end = parse
    "'"                         { fun map i -> P.CHAR(i)           }
  | _                           { fun map i -> 
                                  error lexbuf 
                                    ( "illegal character literal (too many characters): "
                                    ^  get lexbuf
                                    ) 
                                }  
@

% ------------------------------------------------------------------ 
\subsection{Escape Sequences}
% ------------------------------------------------------------------ 

The documentation for \texttt{ocamllex} doesn't say whether ties
are broken in favor of
the longest match, but apparently they are.
<<scan.mll>>=
and escape = parse
    |  escape                   { decode_escape (getchar lexbuf 0) }
    |  ['x' 'X'] hex            { decode_hex (getchar lexbuf 1)    }
    |  ['x' 'X'] hex hex        { decode_hex (getchar lexbuf 1) * 16 + 
                                  decode_hex (getchar lexbuf 2) }
    |  octal                    { decode_hex (getchar lexbuf 0) }
    |  octal octal              { decode_hex (getchar lexbuf 0) * 8 +
                                  decode_hex (getchar lexbuf 1) }
    |  octal octal octal        { decode_hex (getchar lexbuf 0) * 64 +
                                  decode_hex (getchar lexbuf 1) * 8  +
                                  decode_hex (getchar lexbuf 2) }
    | _                         { error lexbuf "illegal escape sequence" }
@
This both depends on the machine we are running on and the target, which
might be different. For now, this implements the Latin-1 on Unix.
<<prolog>>=
let rec decode_escape = function
    | 'a'  -> 7
    | 'b'  -> 8
    | 'n'  -> 10
    | 'r'  -> 13
    | 't'  -> 9
    | '\\' -> 92
    | '\'' -> 39
    | '"'  -> 34
    | '?'  -> 63
    |  _   -> Impossible.impossible "unknown escape sequence"

let decode_hex c = match c with 
    | 'a' .. 'f' -> Char.code c - Char.code 'a' + 10
    | 'A' .. 'F' -> Char.code c - Char.code 'A' + 10
    | '0' .. '9' -> Char.code c - Char.code '0'
    | _          -> Impossible.impossible 
                        ("not a hexadecimal character: "^Char.escaped c)
@
% ------------------------------------------------------------------  
\subsection{Comments}
% ------------------------------------------------------------------  

Comments in C-- originally could nest but for compatibility with the C
preprocessor this feature was droped.  Since it is impossible to
include the character sequence [[*/]] in a C comment C$++$ style
comments are additionally accepted:  a comment starts with [//] and
goes up to the end of the line.  The latter comments are not
implemented with a separate scanner context but inlined.
<<scan.mll>>=
and comment1 = parse
    eof                         { fun map ->
                                  error lexbuf "unterminated comment" 
                                }
  | [^ '*' '\n' '\t' '/']+      { fun map ->
                                  comment1 lexbuf map
                                }
  | nl                          { fun map ->
                                  nl lexbuf map; comment1 lexbuf map 
                                }
  | nl '#'                      { fun map -> 
                                  line lexbuf map 0; comment1 lexbuf map
                                }
  
  | tab                         { fun map -> 
                                  tab lexbuf map; comment1 lexbuf map
                                }
  | "*"                         { fun map ->
                                  comment1 lexbuf map
                                }
  | "*/"                        { fun map ->
                                  token lexbuf map 
                                }
  | _                           { fun map ->
                                  comment1 lexbuf map 
                                }
@

% ------------------------------------------------------------------  
\subsection{Strings}
% ------------------------------------------------------------------  

All escape sequences are handled by the [[escape]] scanner. When the
escape scanner returns we simply continue to scan the string until we
reach the double quote. A string must only contain printable characters;
unfortunately, the lexer specification does not allow to use the
[[printable]] definition inside a character class.
<<scan.mll>>=
and string = parse
    eof                         { fun map buf -> 
                                  error lexbuf "unterminated string" 
                                }
  | "\""                        { fun map buf -> P.STR (Buffer.contents buf) 
                                  (* we are done *)
                                }

  | [^ '\000'-'\031'
       '\128'-'\255'
       '"' '\\' ]+              { fun map buf ->
                                  let s    = get lexbuf              in
                                  ( Buffer.add_string buf s
                                  ; string lexbuf map buf
                                  )
                                }
  | '\\'                        { fun map buf -> 
                                  let i = escape lexbuf in
                                  if i >= 256 then
                                    error lexbuf "character literal too large"
                                  else
                                    ( Buffer.add_char buf (Char.chr(i))
                                    ; string lexbuf map buf
                                    )
                                }    
  | _                           { fun map buf ->
                                  error lexbuf "illegal character in string"
                                }
@

% ------------------------------------------------------------------  
\subsection{Pragmas}
% ------------------------------------------------------------------ 

Pragmas are special because the work on the lexical as well as on the
grammatical level: 
\begin{itemize}
\item A \textit{known} pragma is handled like a keyword -- normal
      scanning and parsing resumes.

\item An \textit{unknown} pragma is skipped by the scanner. 
\end{itemize}
The split personality of pragmas leads to a scanner that uses a
sequence of three scanner contexts to simulate some parsing in case an
unknown pragma must be skipped over.

To decide whether a pragma is known we look at its
\textit{target}---the identifier following the [[pragma]] keyword.
While looking for the identifier white space is skipped and special
characters are noticed. It is an error when no identifier is found.

When an identifier is found but it is not in the [[keywords]] table
the pragma must be skipped by the parser.  This requires to find the
body of the pragma that is enclosed by curly brackets.  Looking for
the opening bracket takes place in the [[pragma2]] scanner context.
<<scan.mll>>=
and pragma1 = parse
    eof                 { fun map -> P.EOF }
  | ws+                 { fun map -> pragma1 lexbuf map }
  | tab                 { fun map -> tab lexbuf map; pragma1 lexbuf map }
  | nl                  { fun map -> nl lexbuf map;  pragma1 lexbuf map } 
  | id                  { fun map -> 
                          let s  = get lexbuf in 
                          try ( match keyword s with 
                              | _     -> pragma2 lexbuf map s
                              )
                          with Not_found -> pragma2 lexbuf map s
                        }
  | _                   { fun map -> 
                          error lexbuf "id for pragma expected" 
                        }


and pragma2 = parse
    eof                 { fun map id -> 
                          error lexbuf "pragma body expected" 
                        }
  | ws+                 { fun map id -> pragma2 lexbuf map id }
  | tab                 { fun map id -> tab lexbuf map; pragma2 lexbuf map id}
  | nl                  { fun map id -> nl  lexbuf map; pragma2 lexbuf map id}
  | '{'                 { fun map id -> 
                          pragma3 lexbuf map 0 
                        }
  | _                   { fun map id -> 
                          error lexbuf "pragma body expected" 
                        }
@
It is an error when the opening bracket is not found. Once it is
found the body of the pragma is skipped over in context [[pragma3]]. A
body of a pragma must contain legal \C~tokens. We don't have to care
for the details but must consider only the following cases:
\begin{itemize}
\item The curly brackets may nest. So we keep a [[level]] to find the
      matching closing bracket.

\item Brackets inside of strings literals, character literals, and
      comments are not considered. Each of these are handled in their
      own scanner contexts.
\end{itemize}
<<scan.mll>>=
and pragma3 = parse
    eof                         { fun map level ->
                                  error lexbuf "unterminated pragma" 
                                }
  | [^ '{' '}'  '\n' '\t' 
       '/' '\'' '"']+           { fun map level ->
                                  pragma3 lexbuf map level
                                }
  | nl                          { fun map level ->
                                  nl lexbuf map
                                ; pragma3 lexbuf map level 
                                }
  | tab                         { fun map level -> 
                                  tab lexbuf map; pragma3 lexbuf map level
                                }
  | '{'                         { fun map level -> 
                                  pragma3 lexbuf map (level+1)
                                }
  | '}'                         { fun map level ->
                                  if   level = 0 
                                  then token lexbuf map
                                  else pragma3 lexbuf map (level-1)
                                }
  | cxxcomment                  { fun map -> pragma3 lexbuf map (* ignore *) } 
  | "/*"                        { fun map level -> 
                                  ignore (comment1 lexbuf map) 
                                ; pragma3 lexbuf map level
                                }
  | "\""                        { fun map level -> 
                                  ignore (string lexbuf map (Buffer.create 80))
                                ; pragma3 lexbuf map level
                                }
  | "'"                         { fun map level -> 
                                  ignore (character lexbuf map)
                                ; pragma3 lexbuf map level
                                }
  
  | _                           { fun map level ->
                                  pragma3 lexbuf map level 
                                }
@

% ------------------------------------------------------------------ 
\subsubsection{C-Style Line Pragma}
% ------------------------------------------------------------------ 

Although not intended it is likely that \C~is used with the C
preprocessor.  It emits directives to link a line in its output to a
another source file.  In principle the [[line]] pragma is intended for
this task.  However, the C preprocessor can not emit this pragmas
instead and thus we provide support for the C preprocessor directive.

The implementation is a new scanner context that requires that the
line directive is matched by the following regular expression (in the
syntax used by \ocaml-Lex and using expressions defined above):
\begin{center}
[[ws* '#' ws+ nat '"'[^ '"']*'"' ws* '\n']]
\end{center}
Note that {\small ANSI/ISO} C allows whitespace before and after the
[[#]] character. Leading whitespace has already been recognized at this
point.

The meaning of a line directive
\texttt{\#}~\textit{line}~\texttt{"}file\texttt{"} is that the
\textit{following} line is on line \textit{line} in file
\textit{file}.  The implementation links the current line to
$\textit{line}-1$ in \textit{file} by placing a sync point.

This implementation does not check the syntax but just recognizes
different tokens. It returns when it finds a string and relies on the
fact that the line number must come first.
<<scan.mll>>=
and line = parse 
    eof                 { fun map l ->
                          error lexbuf "unterminated line directive" 
                        }
  | ws+                 { fun map l -> line lexbuf map l }
  | tab                 { fun map l -> line lexbuf map l }
  | '"'                 { fun map l ->
                          let buf      = Buffer.create 80 in
                          let _        = string lexbuf map buf in
                          let file     = Buffer.contents buf in
                          let pos      = Lexing.lexeme_start lexbuf in
                          let location = file, l-1, 1 in
                                ( Srcmap.sync map pos location
                                ; () (* return *)
                                )
                        }
  | nat                 { fun map l -> 
                          
                          (* inline'ing the l' expression caused an
                          int_of_string failure with ocamlopt *)
                          
                          let l' = int_of_string (get lexbuf)
                          in  line lexbuf map l'
                        }
  | id                  { fun map l ->
                          line lexbuf map l
                        }
  | _                   { fun map l -> 
                          error lexbuf 
                          "illegal character in line directive"
                        }
@

<<scan.mll>>=
{   (* start of epilog *)
    <<scanner entry point>>
@

% ------------------------------------------------------------------  
\subsection{Debugging the Scanner}
% ------------------------------------------------------------------  

In case of an parse error the problem may be actually caused by the
scanner.  For debugging we define a function [[tok2str]] that turns a
token (as defined in [[parse.mli]]) into a string.  This is used below
to define a function that reports the stream of all tokens for a file
together with their positions.
<<scan.mll>>=
    let tok2str = function

    | P.ABORTS            -> "ABORTS"
    | P.ALIGN             -> "ALIGN"
    | P.ALIGNED           -> "ALIGNED"
    | P.ALSO              -> "ALSO"
    | P.AS                -> "AS"
    | P.COLON             -> "COLON"
    | P.CCOLON            -> "CCOLON"
    | P.COMMA             -> "COMMA"
    | P.CONST             -> "CONST"
    | P.CONTINUATION      -> "CONTINUATION"
    | P.CUT               -> "CUT"
    | P.CUTS              -> "CUTS"
    | P.ELSE              -> "ELSE"
    | P.EOF               -> "EOF"
    | P.EQUAL             -> "EQUAL"
    | P.EXPORT            -> "EXPORT"
    | P.FAILS             -> "FAILS"
    | P.FOREIGN           -> "FOREIGN"
    | P.GOTO              -> "GOTO"
    | P.IF                -> "IF"
    | P.IMPORT            -> "IMPORT"
    | P.IN                -> "IN"
    | P.INVARIANT         -> "INVARIANT"
    | P.JUMP              -> "JUMP"
    | P.LBRACE            -> "LBRACE"
    | P.LBRACKET          -> "LBRACKET"
    | P.LPAREN            -> "LPAREN"
    | P.NEVER             -> "NEVER"
    | P.PPERCENT          -> "PPERCENT"
    | P.PRAGMA            -> "PRAGMA"
    | P.RBRACE            -> "RBRACE"
    | P.RBRACKET          -> "RBRACKET"
    | P.READS             -> "READS"
    | P.REGISTER          -> "REGISTER"
    | P.RETURN            -> "RETURN"
    | P.RETURNS           -> "RETURNS"
    | P.RPAREN            -> "RPAREN"
    | P.SECTION           -> "SECTION"
    | P.SEMI              -> "SEMI"
    | P.SPAN              -> "SPAN"
    | P.STACKDATA         -> "STACKDATA"
    | P.TARGETS           -> "TARGETS"
    | P.TO                -> "TO"
    | P.UNICODE           -> "UNICODE"
    | P.UNWINDS           -> "UNWINDS"
    | P.WRITES            -> "WRITES"

    | P.TYPEDEF           -> "TYPEDEF" 
    | P.MEMSIZE           -> "MEMSIZE"
    | P.BYTEORDER         -> "BYTEORDER"
    | P.LIMITCHECK        -> "LIMITCHECK"
    | P.LITTLE            -> "LITTLE"
    | P.BIG               -> "BIG"
    | P.CASE              -> "CASE"
    | P.DEFAULT           -> "DEFAULT"
    | P.TARGET            -> "TARGET"
    | P.DOTDOT            -> "DOTDOT"
    | P.SWITCH            -> "SWITCH"

    | P.WRDSIZE           -> "WORSIZE"
    | P.PTRSIZE           -> "POINTERSIZE"
    | P.FLOATREPR         -> "FLOAT"
    | P.CHARSET           -> "CHARSET"
    

    | P.AMPERSAND(s)      -> "AMPERSAND(" ^ s ^ ")"
    | P.BAR(s)            -> "BAR(" ^       s ^ ")"
    | P.CARET(s)          -> "CARET(" ^     s ^ ")"
    | P.EEQ(s)            -> "EEQ(" ^       s ^ ")"
    | P.GEQ(s)            -> "GEQ(" ^       s ^ ")"
    | P.GGREATER(s)       -> "GGREATER(" ^  s ^ ")"
    | P.GT(s)             -> "GT(" ^        s ^ ")"
    | P.LEQ(s)            -> "LEQ(" ^       s ^ ")"
    | P.LLESS(s)          -> "LLESS(" ^     s ^ ")"
    | P.LT(s)             -> "LT(" ^        s ^ ")"
    | P.MINUS(s)          -> "MINUS(" ^     s ^ ")"
    | P.NEQ(s)            -> "NEQ(" ^       s ^ ")"
    | P.PERCENT(s)        -> "PERCENT(" ^   s ^ ")"
    | P.PLUS(s)           -> "PLUS(" ^      s ^ ")"
    | P.SLASH(s)          -> "SLASH(" ^     s ^ ")"
    | P.STAR(s)           -> "STAR(" ^      s ^ ")"
    | P.TILDE(s)          -> "TILDE(" ^     s ^ ")"
    | P.UMINUS(s)         -> "UMINUS" ^     s ^ ")"
    
    
    | P.ID(s)             -> "ID(" ^        s ^ ")"
    | P.STR(s)            -> "STR(" ^       String.escaped s ^ ")"
    | P.INFIXOP(s)        -> "INFIXOP(" ^   s ^ ")"
    | P.PRIMOP(s)         -> "PRIMOP(" ^    s ^ ")"
    | P.SINT(s)           -> "SINT(" ^       s ^ ")"
    | P.UINT(s)           -> "UINT(" ^       s ^ ")"
    | P.FLT(s)            -> "FLT(" ^       s ^ ")"
    | P.CHAR(i)           -> "CHAR(" ^ Char.escaped (Char.chr i) ^ ")"

    | P.BITSn(i)          -> "BITSn(" ^ string_of_int i ^ ")"

} (* end of epilog *)
@

% ------------------------------------------------------------------  
\section{Grammatical Analysis}\label{sec:parser}
% ------------------------------------------------------------------  

The parser reads a token stream created by the scanner (module
[[Scan]]) and return the abstract syntax of the input, as defined by
module [[Ast]]. 
<<parse.mly>>=
%{
    module A = Ast
    module E = Error

    <<helper functions>>            
%}
@     
[[p]] returns the region for the left hand symbol in the current
production.  A region (of type [[int * int]] contains the position of
the first character character of the symbol in input stream, and the
position of the first character after the symbol.  These regions are
attached to important nodes in the abstract syntax.  The function
[[pn]] returns the region for symbol [[n]] on the right hand side,
where the leftmost symbol has index 1.
<<helper functions>>=
let p  ()  = (Parsing.symbol_start (), Parsing.symbol_end())
let pn n   = (Parsing.rhs_start n, Parsing.rhs_end n)
let px ()  = (Parsing.symbol_start ())

let rev    = List.rev
<<helper functions>>=
let dep msg =
  let deprecated = Reinit.ref false in
  fun x ->
    if not (!deprecated) then
      begin
        Printf.eprintf "C-- warning: %s\n" msg;
        deprecated := true;
      end;
    x

let rdep = dep "Use of 'register' keyword is deprecated"
let noeqdep = dep "Hardware register name without '=' is deprecated"
@ 
<<helper functions>>=
let mkRegs v (hint,ty,regs) = List.map (fun (id,reg) -> (v, hint, ty, id, reg)) regs
let mkTypedefs ty names = List.map (fun n -> A.Typedef(n,ty)) names
@            
The [[[str2uint]] function takes the string representation of an integer
and returns its value.
<<helper functions>>=
let str2uint str =
  let b = Bits.U.of_string str Nativeint.size in
  try Bits.U.to_int b with Bits.Overflow ->
    Error.errorf "constant %s overflows %d-bit native integer" str (Nativeint.size-1)
@         
<<parse.mly>>=
%token ABORTS ALIGN ALIGNED ALSO AS AMPERSAND BIG BYTEORDER CASE COLON CCOLON
%token COMMA CONST CONTINUATION CUT CUTS DEFAULT DOTDOT ELSE EOF EQUAL
%token EXPORT FAILS FOREIGN GOTO IF IMPORT IN INFIXOP INVARIANT JUMP LBRACE
%token LBRACKET LIMITCHECK LITTLE LPAREN MEMSIZE NEVER PPERCENT RBRACE RBRACKET 
%token READS REGISTER RETURN RETURNS RPAREN SECTION SEMI SPAN STACKDATA SWITCH 
%token TARGET TARGETS TO TYPEDEF UNICODE UNWINDS WRITES
%token WRDSIZE PTRSIZE FLOATREPR CHARSET

/* pragmas */

%token PRAGMA

<<parse.mly>>=
/* infix and prefix operators */

%token <string> EEQ NEQ LT LEQ GT GEQ
%token <string> BAR                      
%token <string> CARET                    
%token <string> AMPERSAND                
%token <string> LLESS GGREATER           
%token <string> PLUS MINUS               
%token <string> PERCENT STAR SLASH       
%token <string> TILDE UMINUS                    
%token <string> INFIXOP
%token <string> PRIMOP 

%token <string>         ID
%token <string>         STR
%token <int>            BITSn

%token <string>         SINT
%token <string>         UINT
%token <string>         FLT
%token <int>            CHAR
@
The precedence of tokens from lowest to highest precedence.
<<parse.mly>>=
/* lvalue conflict resolution */
%right      ID
%right      LBRACKET

/* conflict resolution for %foo() and %foo. We ensure the '(' has
   higher precedence and gets shifted. Take the following two
   declarations out and you get a shift/reduce conflict which defaults
   to shifting. This is correct, but we also like to get rid of the
   warning. */
%nonassoc   PRIMOP
%nonassoc   LPAREN

%nonassoc   INFIXOP
%nonassoc   EEQ NEQ LT LEQ GT GEQ
%left       BAR                      
%left       CARET                    
%left       AMPERSAND                
%left       LLESS GGREATER           
%left       PLUS MINUS               
%left       PERCENT STAR SLASH       
%right      TILDE UMINUS

%start program
%type <Ast.program>program

%%

program     :   toplevels                      { rev $1}

toplevels   :   toplevels toplevelAt           { $2::$1 }
            |   /**/                           { []     }
<<parse.mly>>=
toplevelAt  :   toplevel                       { A.ToplevelAt($1,p())       }
toplevel    :   SECTION STR LBRACE sections RBRACE  { A.Section($2, rev $4) }
            |   procedure                      { A.TopProcedure($1)         }
            |   declAt                         { A.TopDecl($1)              }
<<parse.mly>>=
sections    :   sections sectionAt             { $2 :: $1 }
            |   /**/                           { []       }

sectionAt   :   section                        { A.SectionAt($1,p()) }
section     :   procedure                      { A.Procedure($1)     }
            |   datum                          { A.Datum($1)         }
            |   span                           { A.SSpan($1)         }
            |   declAt                         { A.Decl($1)          }

@ 
You might hope to have a nonterminal for an optional type, but this
little optimization leads to shift-reduce conflicts.
<<parse.mly>>=
declAt      :   decl                           { A.DeclAt($1,p()) }   
decl        :   INVARIANT /*----*/ registers SEMI
                    { A.Registers(mkRegs A.Invariant $2) }
            |   /*-----*/ /*----*/ registers SEMI
                    { A.Registers(mkRegs A.Variant $1)   }
            |   INVARIANT REGISTER registers SEMI
                    { rdep (A.Registers(mkRegs A.Invariant $3)) }
            |   /*-----*/ REGISTER registers SEMI
                    { rdep (A.Registers(mkRegs A.Variant $2))   }
          
            |   EXPORT ty exports  SEMI        { A.Export(Some $2, $3) }
            |   EXPORT    exports  SEMI        { A.Export(None,$2)    }
            |   IMPORT ty imports  SEMI        { A.Import(Some $2,$3)           }
            |   IMPORT    imports  SEMI        { A.Import(None,$2)           }
            |   CONST     ID EQUAL exprAt SEMI { A.Const(None,$2,$4)       }
            |   CONST  ty ID EQUAL exprAt SEMI { A.Const(Some $2,$3,$5)    }
            |   TYPEDEF ty names SEMI          { A.Typedef($2,rev $3)      }
            |   TARGET properties SEMI         { A.Target(rev $2)          }
<<parse.mly>>=
uint        : SINT { str2uint $1 }
            | UINT { str2uint $1 }

property    :   MEMSIZE uint                   { A.Memsize $2      }
            |   BYTEORDER BIG                  { A.ByteorderBig    }
            |   BYTEORDER LITTLE               { A.ByteorderLittle }
            |   FLOATREPR STR                  { A.FloatRepr $2    }
            |   CHARSET STR                    { A.Charset $2      }
            |   PTRSIZE uint                   { A.PointerSize $2  }
            |   WRDSIZE uint                   { A.WordSize $2     }

<<parse.mly>>=
properties  :   properties property            { $2 :: $1 }
            |   /**/                           { []       }
<<parse.mly>>=
span        :   SPAN sexprAt exprAt
                LBRACE sections RBRACE         { $2, $3, rev $5 }
<<parse.mly>>=
datumAt     :   datum                          { A.DatumAt($1,p()) }
datum       :   ID COLON                       { A.Label $1 }
            |   ALIGN uint SEMI                { A.Align $2 }
            |   tyAt size opt_initAt SEMI      { A.MemDecl($1,$2,$3)}

opt_initAt : initAt { Some $1 } | { None }
<<parse.mly>>=
initAt      :   init                           { A.InitAt($1,p()) }
init        :   LBRACE   exprs RBRACE          { A.InitExprs($2)  }
            |   LBRACE         RBRACE          { A.InitExprs([])  }
            |   STR                            { A.InitStr($1)    }
            |   string16                       { A.InitUStr($1)   }
<<parse.mly>>=
registers   :   STR    tyAt regs opt_comma     { Some $1, $2, rev $3 }
            |          tyAt regs opt_comma     { None   , $1, rev $2 }

regs        :   regs COMMA ID optEq STR        { ($3, Some $5)::$1 }
            |   regs COMMA ID                  { ($3, None   )::$1 }
            |   ID optEq STR                   { [($1,Some $3)]    }
            |   ID                             { [($1,None   )]    }

optEq       :   { noeqdep () }
            |   EQUAL  { () }

<<parse.mly>>=
size        :   LBRACKET exprAt RBRACKET       { A.FixSize($2) }
            |   LBRACKET       RBRACKET        { A.DynSize     }
            |                                  { A.NoSize      }

procedure   :   conv ID frmls body             {  $1, $2, $3, $4, p() }
            |        ID frmls body             {None, $1, $2, $3, p() }

body        :   LBRACE body0 RBRACE            { rev $2 }

body0       :   body0 bodyAt                   { $2 :: $1 }
            |   /**/                           { []       }

bodyAt      :   body1                          { A.BodyAt($1,p()) }
body1       :   declAt                         { A.DeclBody $1    }
            |   stackdecl                      { A.DataBody $1    }
            |   stmtAt                         { A.StmtBody $1    }

frmls       :   LPAREN  formals RPAREN         { $2 }
            |   LPAREN          RPAREN         { [] }
actls       :   LPAREN  actuals RPAREN         { $2 }
            |   LPAREN          RPAREN         { [] }

formals     :   formals_ opt_comma             { rev $1   }
formals_    :   formals_ COMMA formal          { $3 :: $1 }
            |   formal                         { [$1]     }

actuals     :   actuals_ opt_comma             { rev $1   }
actuals_    :   actuals_ COMMA actual          { $3 :: $1 }
            |   actual                         { [$1]     }

formal      :   bare_formal                    { p(), $1 }
bare_formal :   opt_kind opt_invariant opt_register tyAt ID opt_aligned
                { $1, $2, $4, $5, $6 }

opt_kind : STR { Some $1 } | { None }
opt_invariant : INVARIANT { A.Invariant } | { A.Variant }
opt_register  : REGISTER { () } | { () }

cformal     :   opt_kind ID opt_aligned        { p(), $1, $2, $3 }

cformals    :   cformals_ opt_comma            { rev $1   }
            |   /**/      opt_comma            { []       }
cformals_   :   cformals_ COMMA cformal        { $3 :: $1 }
            |   cformal                        { [$1]     }

actual      :   opt_kind exprAt opt_aligned    { $1, $2, $3 }
<<parse.mly>>=
stackdecl   :   STACKDATA LBRACE data RBRACE   { rev $3 }

data        :   data  datumAt                  { $2 :: $1 }
            |   /**/                           { []       }

conv        :   FOREIGN STR                    { Some $2 }

aligned     :   ALIGNED uint                   { $2 }

flowAt      :   flow                           { A.FlowAt($1,p()) }
flow        :   ALSO CUTS     TO names         { A.CutsTo($4)     }
            |   ALSO UNWINDS  TO names         { A.UnwindsTo($4)  }
            |   ALSO RETURNS  TO names         { A.ReturnsTo($4)  }
            |   ALSO ABORTS                    { A.Aborts         }
            |   NEVER RETURNS                  { A.NeverReturns   }

flows       :   flows flowAt                   { $2 :: $1 }
            |   /**/                           { []       }

targets     :   TARGETS names                  { $2 }
            |   /**/                           { [] }

aliasAt     :   alias                          { A.AliasAt($1,p()) }
alias       :   READS  opt_names               { A.Reads ($2)       }
            |   WRITES opt_names               { A.Writes($2)       }

procanns    :   procanns flowAt                { A.Flow  $2 :: $1 }
            |   procanns aliasAt               { A.Alias $2 :: $1 }
            |   /**/                           { []       }
@

The grammar uses [[nameOrMem]] not only at the left hand side of
assignments but also as part of expressions where they denote the values
of registers and memory.  The introduction of hints for registers
(implemented as [[opstr ID]] or similar) has lead to serious
reduce/reduce conflicts caused by the use of [[nameOrMemAt]] in
[[sexpr]].  One way of getting rid of them was to split the original
[[nameOrMemAt]] into [nameOrMemAt0]] and [[nameOrMemAt]]:
[[nameOrMemAt0]] does not include [[STR ID]] which is not needed for
[[sexpr]].


<<parse.mly>>=
nameOrMemAt :   nameOrMem                      { A.NameOrMemAt($1,p()) } 
nameOrMem   :   nameOrMem0                     { $1 } 
            |   ID aligned                     { A.Name(None, $1, Some $2) }
            |   STR ID opt_aligned             { A.Name(Some $1,$2,$3) } 
            
<<helper functions>>=
let ast_mem ty exp (align, alias) = A.Mem(ty, exp, align, alias)
<<parse.mly>>=
nameOrMemAt0:   nameOrMem0                    { A.NameOrMemAt($1,p()) }
nameOrMem0  :   ID                            { A.Name(None, $1, None)}
            |   mem_type LBRACKET exprAt mem_properties RBRACKET { ast_mem $1 $3 $4 }

mem_type : sty { $1 }
         | ID  { A.TypeSynonym($1) }

mem_properties : aligned opt_in_ids { (Some $1, $2) }
               | IN ids opt_aligned { ($3, $2) }
               |                    { (None, []) }

opt_aligned : { None } | aligned { Some $1 }
opt_in_ids  : { [] } | IN ids { $2 }
ids         : ID { [$1] }
            | ID COMMA ids { $1 :: $3 }


nameOrMems  :   nameOrMems_ opt_comma          { rev $1   }
nameOrMems_ :   nameOrMems_ COMMA nameOrMemAt  { $3 :: $1 }
            |   nameOrMemAt                    { [$1]     }

tyAt        :   ty                             { A.TyAt($1,p()) }
ty          :   sty                            { $1             }
            |   ID                             { A.TypeSynonym($1)  }

sty         :   BITSn                          { A.BitsTy($1)     }

returnto    :   LT sexprAt SLASH sexprAt GT    { Some($2,$4) }
            |   /**/                           { None        }
<<parse.mly>>=
stmtAt      :   stmt                           { A.StmtAt($1,p())     }
stmt        :   SEMI                           { A.EmptyStmt          }
            |   ID COLON                       { A.LabelStmt $1       }
            |   SPAN sexprAt sexprAt body      { A.SpanStmt($2,$3,$4) }
            |   nameOrMems EQUAL exprs SEMI       
                { A.AssignStmt($1,List.map (fun e -> None,e) $3)  }

            |   nameOrMems EQUAL conv PPERCENT ID actls flows SEMI
                { A.PrimStmt($1, $3, $5, $6, rev $7) }      
            
            |                 conv PPERCENT ID actls flows SEMI
                { A.PrimStmt([], $1, $3, $4, rev $5) }      
            
            |   nameOrMems EQUAL conv expr actls targets procanns SEMI
                { A.CallStmt($1, $3, $4, $5, $6, rev $7)  }
            
            |                 conv expr actls targets procanns SEMI
                { A.CallStmt([], $1, $2, $3, $4, rev $5)  }
                                          
            |   nameOrMems EQUAL      PPERCENT ID actls flows SEMI
                { A.PrimStmt($1, None, $4, $5, rev $6)    }
            
            |                      PPERCENT ID actls flows SEMI
                { A.PrimStmt( [], None, $2, $3, rev $4)}
            
            |   nameOrMems EQUAL      expr actls targets procanns SEMI
                { A.CallStmt($1, None, $3, $4, $5, rev $6)}

            |                      expr actls targets procanns SEMI
                { A.CallStmt([], None, $1, $2, $3, rev $4)}
 
            |   IF exprAt body                      {A.IfStmt($2,$3,[])}
            |   IF exprAt body  ELSE body           {A.IfStmt($2,$3,$5)}
            |   GOTO exprAt targets SEMI            {A.GotoStmt($2,$3)}
            |   CONTINUATION ID LPAREN cformals RPAREN COLON
                                                    {A.ContStmt($2,$4)}
            |   CUT TO expr actls flows SEMI        {A.CutStmt($3,$4, rev $5)  }
            |   LIMITCHECK exprAt limitfailure SEMI {A.LimitcheckStmt($2,$3)  }
            |   conv JUMP exprAt       targets SEMI {A.JumpStmt($1  ,$3,[],$4) }
            |        JUMP exprAt       targets SEMI {A.JumpStmt(None,$2,[],$3) }
            |   conv JUMP exprAt actls targets SEMI {A.JumpStmt($1  ,$3,$4,$5) }
            |        JUMP exprAt actls targets SEMI {A.JumpStmt(None,$2,$3,$4) }
            |   conv RETURN returnto       SEMI     {A.ReturnStmt($1  ,$3,[])  }
            |        RETURN returnto       SEMI     {A.ReturnStmt(None,$2,[])  }
            |   conv RETURN returnto actls SEMI     {A.ReturnStmt($1  ,$3,$4)  }
            |        RETURN returnto actls SEMI     {A.ReturnStmt(None,$2,$3)  }
            |   SWITCH srange expr LBRACE arms RBRACE  
                        {A.SwitchStmt($2,$3, rev $5)}

<<parse.mly>>=
limitfailure : FAILS TO exprAt {Some $3}
            |  /**/            {None}
<<parse.mly>>=
srange      :   LBRACKET range RBRACKET        {Some $2}
            |   /**/                           {None}

range       :   expr                           {A.Point $1     }
            |   expr DOTDOT expr               {A.Range ($1,$3)}

ranges      :   ranges_                        { rev $1 }
            |   ranges_ COMMA                  { rev $1 }
            |   /**/                           { [] } 

ranges_     :   ranges_ COMMA range            { $3 :: $1 } 
            |   range                          { [$1]     } 

arms        :   arms armAt                     { $2 :: $1  }
            |   /**/                           { []        }

armAt       :   arm                            { A.ArmAt($1,p()) }
arm         :   CASE ranges COLON body         { A.Case($2,$4)   } 

<<parse.mly>>=
sexprAt     :   sexpr                          { A.ExprAt($1, p()) }
sexpr       :   SINT opt_colon_ty              { A.Sint ($1, $2)   }
            |   UINT opt_colon_ty              { A.Uint ($1, $2)   }
            |   FLT  opt_colon_ty              { A.Float($1, $2)   }
            |   CHAR opt_colon_ty              { A.Char ($1, $2)   }
            |   nameOrMemAt0                   { A.Fetch $1        }
           /*   allow to write nullary OPs like constants */
            |   PRIMOP                         { A.PrimOp($1,[])   }
            |   LPAREN exprAt RPAREN           { $2                }
opt_colon_ty : CCOLON tyAt { Some $2 } | { None }
<<parse.mly>>=
exprAt      :   expr                           { A.ExprAt($1, p())    }
expr:       |   sexpr                          { $1                   }
            |   PRIMOP actls                   { A.PrimOp($1,$2)      }

            |   exprAt PLUS       exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt MINUS      exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt PERCENT    exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt STAR       exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt SLASH      exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt LLESS      exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt GGREATER   exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt CARET      exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt BAR        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt AMPERSAND  exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt EEQ        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt NEQ        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt LT         exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt LEQ        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt GEQ        exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt GT         exprAt       { A.BinOp($1,$2,$3) }
            |   exprAt INFIXOP    exprAt       { A.PrimOp($2,[None,$1,None;
                                                              None,$3,None]) }
            |   TILDE exprAt %prec TILDE       { A.UnOp($1,$2)     }
            |   MINUS exprAt %prec UMINUS      { uminus $2         }

exprs       :   exprs_ opt_comma               { rev $1   }
exprs_      :   exprs_ COMMA exprAt            { $3 :: $1 }
            |   exprAt                         { [$1]     }
<<helper functions>>=
let uminus e =
  let rec strip = function
    | A.ExprAt(e, _) -> strip e
    | A.Sint(s, w) -> A.Sint("-" ^ s, w)
    | _ -> A.UnOp("-", e) in
  strip e
<<parse.mly>>=
imports     :   imports_ opt_comma             { rev $1           }
imports_    :   imports_ COMMA STR AS ID       { (Some $3,$5)::$1 }
            |   imports_ COMMA        ID       { (None   ,$3)::$1 } 
            |   STR AS ID                      { [Some $1,$3]     }
            |   ID                             { [None   ,$1]     }

exports     :   exports_ opt_comma             { rev $1           }
exports_    :   exports_ COMMA ID AS STR       { ($3,Some $5)::$1 }
            |   exports_ COMMA ID              { ($3,None)::$1    }
            |   ID AS STR                      { [$1,Some $3]     }
            |   ID                             { [$1,None]        }

names       :   names_ opt_comma               { rev $1 }
names_      :   names_ COMMA ID                { $3:: $1}
            |   ID                             { [$1] }

opt_names   :   names { $1 }
            |   /**/  { [] }

opt_comma   :   COMMA                          {}
            |   /**/                           {}

string16    :   UNICODE LPAREN STR RPAREN      { $3 }
@
