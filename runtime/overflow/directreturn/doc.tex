\documentclass[twoside,12pt]{article}

\input{../../../config/macros.tex}
\usepackage{noweb}
\pagestyle{noweb}
\noweboptions{shift}
%\noweboptions{breakcode}
\author{Daniel Peng and Norman Ramsey}
\title{Quick C-- Overflow Handling and Stack Manipulation}
\begin{document}

\maketitle

\ifhtml\else\tableofcontents\fi

\section{Introduction}

Parallelism is becoming increasingly important.  We face two seemingly contradictory challenges in exploiting this parallelism.  First, compilers cannot identify logical parallelism in existing serial programs, so these programs cannot exploit parallelism.  Second, programmers can easily write programs with embarassingly large amounts of parallism, which rapidly overwhelms the number of available processors.  To manage this parallelism, the compiler can statically decide what parallel forks should actually execute in serial; or, the program can dynamically decide (at runtime) what parallel forks should actually execute in serial.  Deciding at runtime allows the program to use runtime information (for example, processor utilization) to make the correct decision.

{\PAL} is intended to encapsulate a retargetable, optimizing back end.  This technology is well understood but difficult to implement, which makes it worth trying to reuse.  {\PAL} includes both a compile-time interface, which is used by the front end to generate code, and a run-time interface, which is used by a run-time system to support such language features as exception dispatch and garbage collection.

Future language designers will target {\PAL} to leverage the robust code generation and optimization that {\PAL} encapsulates.  To make this a viable plan, {\PAL} must provide primitives to support dynamic parallelism.  Hence, we would like to extend {\PAL}'s compile-time and run-time interfaces to support dynamic parallelism.

We also speculate that language implementors can use the same primitives to implement apparently unrelated features like incremental garbage collection or efficient first-class continuations.  We believe that stack manipulation (i.e., control flow manipulation/continuation manipulation) is somehow fundamental to many of these problems.  Dynamic parallelism is a manipulation of control flow: fork or don't fork.  Likewise, first-class continuations and one-shot continuations can be implemented efficiently by lazily copying the stack stack copying, and lazy copying are all manipulations of control flow.  (Although stack copying and lazy copying are implementation techniques for first-class continuations and one-shot continuations.)  Finally, multiple stacklets and overflow/underflow handling are essential to lightweight concurrency, since we cannot give thousands of threads a full-sized 4K stack.  We must be able to dynamically allocate on overflow and deallocate on underflow.

Our work is guided by an analysis of two motivating examples.  Goldstein's thesis gives a broad survey of control-flow structures for parallel programs.  In particular, we adopt his parallel-ready serial call as the fundamental primitive for dynamic parallelism.  Unfortunately, Goldstein relies on special hardware support (a message-passing machine) to synchronize threads.
Cilk adopts many of Goldstein's ideas, but it restricts the programmer to a fork/join framework  so that it can be compiled to portable C on standard hardware, with only minimal assembly code to provide synchronization.  Cilk is forced to maintain a separate parallel deque of activation frames alongside the C stack.  Perhaps Cilk can be compiled to more efficient C--, using better primitives for manipulating control flow in the program.


\subsection{Goldstein}

Goldstein gives many different techniques for implementing dynamic parallelism
efficiently.  We focus on a technique that Goldstein calls lazy thread forks,
parallel-ready serial calls, or prscalls for short.  A parallel-ready serial call
behaves like a standard serial call, except that if extra processors are
available, the caller can be stolen and executed as a new thread.  The caller
can use the return values after a ``join,'' which blocks the caller until all
the callees complete (this is a no-op in the serial case).

The callee communicates with the caller by way of ``inlets.''   Inlets are functions that run with
their own stack frame at the youngest end of the stack, but they also have
access to the parent frame and its local variables. Thus, inlets can deposit return values in the parent frame.  Inlets also implement the ``join'' operation by decrementing a count of pending children upon return and resuming the parent when the count hits 0.\footnote{Parent-controlled return continuations optimize this join operation.  Rather than branching on the count of pending children, each child changes the return continuation of every other child when it returns.  Since this scales as $O(n^2)$, Goldstein only applies this for 2 outstanding children.}  Goldstein guarantees that an inlet runs atomically with respect to other inlets as well as to the parent code.  Goldstein uses hardware support to provide this.\footnote{Eicken, Culler, et al.  Active Messages: a Mechanism for Integrated Communication and Computation.  \url{http://www.cs.berkeley.edu/~culler/papers/isca92.ps}}

The work appears to be distinguished from our {\PAL} conversations by
these key design decisions:
\begin{enumerate}
\item Threads are 'non-preemptive', which limits possible race conditions.
\item  It is possible for an activation to call a procedure on a new
    stack (or segment) *without* making a call on its own stack.
\item The system reserves a special 'top' register, which among its
    other functions enables an activation to know when it is safe to
    make a call on its own stack.
\end{enumerate}
The system uses a more refined model of the lifetime of an activation:
In {\PAL} 2.0, an activation dies when control reaches an older
activation on the same stack.  In Goldstein's system, an activation
dies when an older activation on the same stack *segment* makes a call
on that segment.

In {\PAL}, the stack pointer plays two roles: it provides access to an
activation's private data, and it marks the boundary between allocated
and unallocated space on the current stack (segment).  In Goldstein's
system, the second role is played by the 'top' pointer.  When the top
pointer and stack pointer are different, it is unsafe to make a call
on one's own stack.  (The top pointer is also used to help link stack
segments.)

Every thread has a 'stub' that stores various bits of state, including
a pointer to its parent thread.  His abstract machine uses this
pointer to directly schedule the parent thread when the child
suspends, without alternate-returning at all.  On p. 57, Goldstein
says that this stub is stored in its base frame.  For threads that
start a new stacklet, this stub is at the bottom, so you could use the
same-size stacklet and alignment trick to get to the stub.  For a lazy
thread, this stub is in the middle of some stack, so you can't do
that.  Goldstein probably burns a register to store the location of the stub,
but it's unclear.

\subsection{Cilk}

Cilk conservatively extends C with support for parallel-ready serial call.  Cilk restricts Goldstein's prscall so that Cilk can be compiled to portable C; with this restricted prscall, Cilk calls itself a Fork/Join framework.  These are the restrictions:
\begin{enumerate}
\item The parent must join all its children before returning.
\item A child synchronizes with its parent only when the child terminates and when the parent joins.
\end{enumerate}
With these restrictions, Cilk's fork/join is equivalent to a parallel-let construct.

Cilk is interesting as a test case because it implements the work-stealing and
atomic inlets from Goldstein's work, but it compiles to portable C without any
special hardware support for synchronization.  Cilk pays a price; since it
can't manipulate the C stack, it needs to maintain an explicit stack of
activation frames and copy C local variables to and from the explicit stack.
(These are actual copies to and from memory, not just register manipulation.)
This makes it an interesting test case for C-- parallelism and stack
manipulation primitives; Cilk has solved the thorny synchronization issues, but
it might benefit from good parallelism and stack manipulation primitives.  Would compiling Cilk to C-- be faster or easier?

Cilk plays a neat trick for synchronization.  Cilk inlets are only called at child termination, and child termination is only guaranteed when the parent joins.  Hence, the Cilk runtime's strategy is to queue up inlet invocations and invoke them at join points.

More specifically, every
inlet is compiled into a function, and the function is actually
invoked on the parent stack after completion of the child (this is
slightly different from Goldstein).  The Cilk compiler generates three
versions of each inlet:
\begin{enumerate}
\item a fast version that runs when the parent has not been stolen.  No
   synchronization is necessary, since execution is serial.
\item a slow version that runs when the child was spawned _after_
   the parent was stolen (so they are still on the same stack).  No
   synchronization is necessary, since execution is serial.
\item a "slowest" version that runs when the child was spawned _before_
   the parent was stolen (so they are on different stacks).  Now
   invocations of the "slowest" version are queued up and run
   when the parent joins.  The code for this is at
   \url{http://www.koders.com/c/fid11BFBECAE209C9B8F2B558F8FBB04205799FFCE8.aspx}.
\end{enumerate}

So now the remaining question is how does Cilk guarantee that a child
doesn't return while the parent is being stolen?  They maintain a
deque of activation frames and designed the "THE protocol" that is
lock-free in the common case when the two ends of the deque are far
apart.  The deque largely parallels the stack; it doesn't replace the
stack.

This shadow deque is expensive; at every prscall, the caller must be stolen, so local variables on the C stack must be flushed to the shadow deque.  (However, local variables need not be copied \emph{out} of the shadow deque unless the caller is actually stolen.)



\let\osection=\section
\def\section{\clearpage\osection}

\input{invokeclosure.inc}

\end{document}

